{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vGblcG_sCx3j",
        "YLXHMvWcDIYN",
        "1zo1bANmC1Or",
        "x8Sjgu12C5cb",
        "Owiy9tFgDppu",
        "Rjzz7tdVDevu",
        "-RCwDkMJDQab",
        "p8arZfcOES5Z",
        "xncDXu5SEZvE"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Instalando bibliotecas"
      ],
      "metadata": {
        "id": "vGblcG_sCx3j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62DX_QSKGa_i"
      },
      "outputs": [],
      "source": [
        "!pip install -U image-classifiers==1.0.*\n",
        "!pip install -U efficientnet==1.0.*\n",
        "!pip install -U segmentation-models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Incluido as máscaras e imagens no ambiente atual"
      ],
      "metadata": {
        "id": "YLXHMvWcDIYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/gdrive/MyDrive/Projeto Odonto/Images-02.zip\"\n",
        "!unzip \"/content/gdrive/MyDrive/Projeto Odonto/Masks-02.zip\""
      ],
      "metadata": {
        "id": "fZwT_HT4AM5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "bdz5AJUq1Nsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c108350b-3031-4e5b-83e8-cbca7e7d3295"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importando bibliotecas"
      ],
      "metadata": {
        "id": "1zo1bANmC1Or"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, transform, util\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import segmentation_models as sm\n",
        "import random\n",
        "import datetime\n",
        "import math\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "c1t-KwBOFfb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64e0ae7a-3eef-4e80-cc3e-a4fad238139c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmentation Models: using `keras` framework.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Declarando uma classe Dataset de apoio"
      ],
      "metadata": {
        "id": "x8Sjgu12C5cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(tf.keras.utils.Sequence):\n",
        "  def __init__(self, x_set, y_set, batch_size, size:tuple=(512,512)):\n",
        "    self.x, self.y = x_set, y_set\n",
        "    random.shuffle(self.x)\n",
        "    self.batch_size = batch_size\n",
        "    self.size = size\n",
        "\n",
        "  def __len__(self):\n",
        "    return math.ceil(len(self.x) / self.batch_size)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "\t\t#batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "\n",
        "    imgs = []\n",
        "    masks = []\n",
        "\n",
        "    for filename_img in batch_x:\n",
        "      img = io.imread(filename_img, as_gray=True)\n",
        "\t\t\t#cropped_imgs = crop_img_into_imgs(img, self.size)\n",
        "      imgs.append(transform.resize(img, self.size))\n",
        "\n",
        "      masks_ = []\n",
        "\t\t\t#masks_ = [ [] for _ in range(len(cropped_imgs)) ]\n",
        "      mask_path = filename_img.split('/')[-1].split('.')[0]\n",
        "      mask_path = glob.glob(os.path.join(self.y, mask_path, '*'))\n",
        "\n",
        "      for filename_mask in mask_path:\n",
        "        mask = io.imread(filename_mask, as_gray=True)\n",
        "        masks_.append(transform.resize(mask, self.size))\n",
        "\t\t\t\t#cropped_masks = crop_img_into_imgs(mask, self.size)\n",
        "\n",
        "\t\t\t\t#for i, cropped_mask in enumerate(cropped_masks):\n",
        "\t\t\t\t#\tmasks_[i].append(cropped_mask)\n",
        "\t\t\t\t\n",
        "\t\t\t#masks_ = [ np.array(mask).swapaxes(0, -1) for mask in masks_ ]\n",
        "      masks_ = np.array(masks_).swapaxes(0, -1)\n",
        "\n",
        "\t\t\t#imgs.extend(cropped_imgs)\n",
        "\t\t\t#masks.extend(masks_)\n",
        "      masks.append(masks_)\n",
        "\t\t\n",
        "    imgs = np.array(imgs)\n",
        "    imgs = np.expand_dims(imgs, -1)\n",
        "\t\t#print(imgs.shape)\n",
        "    masks = np.array(masks)\n",
        "\n",
        "    return imgs, masks\n",
        "\n",
        "  def split(self, split_rate):\n",
        "    splitted_x = self.x[:math.ceil(split_rate * len(self.x))]\n",
        "    self.x = self.x[math.ceil(split_rate * len(self.x)):]\n",
        "\n",
        "    return Dataset(splitted_x, self.y, math.ceil(split_rate * self.batch_size), self.size)"
      ],
      "metadata": {
        "id": "TAiB5AvCT0dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pré-processamento das imagens"
      ],
      "metadata": {
        "id": "j4iwUujeDA9e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Métodos de apoio para a obtencao das imagens e mascaras no tamanho correto"
      ],
      "metadata": {
        "id": "Owiy9tFgDppu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_img(img:np.ndarray, size:tuple):\n",
        "\timg_padded = np.pad(img, ( (0, size[0] - img.shape[0]), (0, size[1] - img.shape[1])), 'constant', constant_values=(0))\n",
        "\treturn img_padded\n",
        "\n",
        "def crop_img_into_imgs(img:np.ndarray, size:tuple) -> list:\n",
        "\tmult_x = img.shape[0] / size[0]\n",
        "\tmult_y = img.shape[1] / size[1]\n",
        "\t\n",
        "\timg_padded = pad_img(img, (size[0] * math.ceil(mult_x), size[1] * math.ceil(mult_y)))\n",
        "\n",
        "\timgs = []\n",
        "\n",
        "\tfor i in range(math.ceil(mult_x)):\n",
        "\t\tfor j in range(math.ceil(mult_y)):\n",
        "\t\t\timgs.append(img_padded[(i * size[0]):((i + 1) * size[0]), (j * size[1]):((j + 1) * size[1])])\n",
        "\t\t\n",
        "\treturn imgs"
      ],
      "metadata": {
        "id": "rQQdI4TI6e02"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregando as imagens e máscaras"
      ],
      "metadata": {
        "id": "Rjzz7tdVDevu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_img_and_masks(img_location, masks_location, size=(512,512), multiple_masks=True):\n",
        "  id = img_location.split('/')[-1].split('.')[0]\n",
        "  masks_location = glob.glob(os.path.join(masks_location, id, '*'))\n",
        "  masks = []\n",
        "\n",
        "  img = io.imread(img_location, as_gray=True)\n",
        "  img = transform.resize(img, size)\n",
        "\t#imgs = crop_img_into_imgs(img, size)\n",
        "\t#masks = [ [] for _ in range(len(imgs)) ]\n",
        "\n",
        "  for mask_location in masks_location:\n",
        "    mask = io.imread(mask_location, as_gray=True)\n",
        "    masks.append(transform.resize(mask, size))\n",
        "\t\t#cropped_masks = crop_img_into_imgs(mask, size)\n",
        "\n",
        "\t\t#for i, cropped_mask in enumerate(cropped_masks):\n",
        "\t\t#\tmasks[i].append(cropped_mask)\n",
        "\t\t\t\n",
        "\t# tranforma uma lista de mascaras em uma mascara com o numero de canais igual a quantidade de mascaras\n",
        "\t#print(np.array(masks).shape)\n",
        "\t#print(np.ndarray(masks).shape)\n",
        "\t#masks = [ np.array(mask).swapaxes(0, -1) for mask in masks ]\n",
        "  masks = np.array(masks).swapaxes(0, -1)\n",
        "\t\t\n",
        "  return img, masks\n",
        "\n",
        "def load_data(imgs_path:list, masks_path:str, size:tuple):\n",
        "\timgs_path = imgs_path\n",
        "\timgs = []\n",
        "\tmasks = []\n",
        "\n",
        "\tfor img_path in imgs_path:\n",
        "\t\tx, y = load_img_and_masks(img_path, masks_path, size)\n",
        "\t\timgs.append(x)\n",
        "\t\tmasks.append(y)\n",
        "\n",
        "\treturn imgs, masks\n",
        "\n",
        "def preprocess_data(imgs, masks):\n",
        "  imgs = np.array(imgs)\n",
        "  imgs = np.expand_dims(imgs, -1)\n",
        "\n",
        "  masks = np.array(masks)\n",
        "\n",
        "  return imgs, masks"
      ],
      "metadata": {
        "id": "GSDQgDJcHBhx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aumento de dados\n"
      ],
      "metadata": {
        "id": "-RCwDkMJDQab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rotate_img_mask(img:np.ndarray, masks:np.ndarray, angle:float):\n",
        "\trotated_img = transform.rotate(img, angle)\n",
        "\trotated_masks = transform.rotate(masks, angle)\n",
        "\n",
        "\treturn rotated_img, rotated_masks\n",
        "\n",
        "def rotate_imgs_masks(imgs:list, masks:list, angle:float):\n",
        "\trotated_imgs = []\n",
        "\trotated_masks = []\n",
        "\n",
        "\tfor i, img in enumerate(imgs):\n",
        "\t\trotated_img, rotated_mask = rotate_img_mask(img, masks[i], angle)\n",
        "\t\trotated_imgs.append(rotated_img)\n",
        "\t\trotated_masks.append(rotated_mask)\n",
        "\n",
        "\treturn rotated_imgs, rotated_masks\n",
        "\n",
        "def fliplr_img_mask(img:np.ndarray, mask:np.ndarray) -> tuple:\n",
        "\tflipped_img = np.fliplr(img)\n",
        "\tflipped_mask = np.fliplr(mask)\n",
        "\t\n",
        "\treturn flipped_img, flipped_mask\n",
        "\n",
        "def fliplr_imgs_masks(imgs:list, masks:list) -> tuple:\n",
        "\tflipped_imgs = []\n",
        "\tflipped_masks = []\n",
        "\tfor img, mask in zip(imgs, masks):\n",
        "\t\tflipped_img, flipped_masks_ = fliplr_img_mask(img, mask)\n",
        "\t\tflipped_imgs.append(flipped_img)\n",
        "\t\tflipped_masks.append(flipped_masks_)\n",
        "\n",
        "\treturn flipped_imgs, flipped_masks\n",
        "\n",
        "def random_noise_imgs_masks(imgs:list, masks:list, mode='gaussian') -> tuple:\n",
        "\tnoised_imgs = []\n",
        "\tfor img in imgs:\n",
        "\t\tnoised_imgs.append(util.random_noise(img, mode))\n",
        "\n",
        "\treturn noised_imgs, masks"
      ],
      "metadata": {
        "id": "ol8ZyJoW6jGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definindo o modelo, compilando e treinando"
      ],
      "metadata": {
        "id": "Knt08PrxEKc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm.set_framework('tf.keras')\n",
        "\n",
        "model = sm.Unet(classes=6, activation='sigmoid', input_shape=(None, None, 1), encoder_weights=None)\n",
        "\n",
        "model.compile('Adam', loss=sm.losses.bce_jaccard_loss, metrics=[sm.metrics.iou_score])\n",
        "\n",
        "horario = datetime.datetime.now()\n",
        "\n",
        "callbacks = [ tf.keras.callbacks.ModelCheckpoint(f'./Backups/Models/{horario.isoformat()}.hdf5', save_best_only=True),\n",
        "              tf.keras.callbacks.EarlyStopping(monitor='val_iou_score', patience=4),\n",
        "              tf.keras.callbacks.TensorBoard(log_dir='./log', write_images=True) ]\n",
        "\n",
        "imgs_path = random.sample(glob.glob('/content/Images-02/*'), 151)\n",
        "masks_path = '/content/Masks-02/'"
      ],
      "metadata": {
        "id": "WBnBmIaHImhB"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs, masks = load_data(imgs_path, masks_path, (512,512))\n",
        "print(len(imgs))\n",
        "print(len(masks))"
      ],
      "metadata": {
        "id": "d7varN7uMyjf"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = preprocess_data(imgs, masks)\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExBYP7W_MxNE",
        "outputId": "57dc4dca-1f9f-471c-bc44-a7ae6c0dcae5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(151, 512, 512, 1)\n",
            "(151, 512, 512, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y, batch_size=5, epochs=10, validation_split=0.2, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gscSdcvMvN_",
        "outputId": "e296cac9-1b79-4daf-c777-0b085c472e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "24/24 [==============================] - 1699s 71s/step - loss: 1.2706 - iou_score: 4.3377e-05 - val_loss: 1.0108 - val_iou_score: 1.1813e-05\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - 1689s 71s/step - loss: 1.0669 - iou_score: 4.2904e-05 - val_loss: 1.0551 - val_iou_score: 3.3517e-05\n",
            "Epoch 3/10\n",
            "24/24 [==============================] - 1695s 71s/step - loss: 1.0277 - iou_score: 4.2456e-05 - val_loss: 1.0872 - val_iou_score: 4.1306e-05\n",
            "Epoch 4/10\n",
            "24/24 [==============================] - 1690s 71s/step - loss: 1.0162 - iou_score: 4.2357e-05 - val_loss: 1.0712 - val_iou_score: 4.3858e-05\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - 1693s 71s/step - loss: 1.0111 - iou_score: 4.2048e-05 - val_loss: 1.0344 - val_iou_score: 4.1846e-05\n",
            "Epoch 6/10\n",
            "24/24 [==============================] - 1808s 76s/step - loss: 1.0083 - iou_score: 4.1684e-05 - val_loss: 1.0176 - val_iou_score: 4.0987e-05\n",
            "Epoch 7/10\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.0064 - iou_score: 4.1285e-05  "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verificando o modelo treinado"
      ],
      "metadata": {
        "id": "p8arZfcOES5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_img = io.imread('/content/imagem-001.jpg', as_gray=True)\n",
        "predict_img = transform.resize(predict_img, (512,512))\n",
        "predict_img = np.expand_dims(predict_img, 2)\n",
        "predict_img = np.expand_dims(predict_img, 0)\n",
        "print(predict_img.shape)\n",
        "\n",
        "predicted_mask = model.predict(predict_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdMVd5pbu544",
        "outputId": "3313ec93-dd93-4de7-83ae-7a85eecf15c4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 512, 512, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(predicted_mask[0,:,:,5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "RIL10sQodr9a",
        "outputId": "d983588a-fb7a-4dc4-9e7a-2f3e49f331b1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ffa305a1590>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Salvando o modelo"
      ],
      "metadata": {
        "id": "xncDXu5SEZvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model1.hdf5')"
      ],
      "metadata": {
        "id": "78pRO0fYv16U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}